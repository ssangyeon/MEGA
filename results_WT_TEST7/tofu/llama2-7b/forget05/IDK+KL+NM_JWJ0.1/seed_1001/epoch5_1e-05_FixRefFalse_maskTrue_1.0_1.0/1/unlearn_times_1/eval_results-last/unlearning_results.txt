Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.4313790690556778
Real Authors Truth Ratio: 0.5406597054072757
Real Authors Token Entropy: 0.9556224546955638
Real Authors Cosine Similarity: 0.02393214264884591
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.0
Real World Probability: 0.42698422516139667
Real World Truth Ratio: 0.5104519052881447
Real World Token Entropy: 0.9695678375074898
Real World Cosine Similarity: 0.009962695053754708
Real World Entailment Score: 0.0
Retain ROUGE: 0.009258055295400103
Retain Probability: 0.5561070020310201
Retain Truth Ratio: 0.37361442334170747
Retain Token Entropy: 0.9472085241630691
Retain Cosine Similarity: 0.050387556487694385
Retain Entailment Score: 0.0
Forget ROUGE: 0.01317577503376012
Forget Probability: 0.4513977328049872
Forget Truth Ratio: 0.3363319007272739
Forget Token Entropy: 0.9493360645527739
Forget Cosine Similarity: 0.04033823358360678
Forget Entailment Score: 0.0
Model Utility Retain: 0.0
Model Utility: 0.0
Forget Efficacy: 0.8317512715700743
Model Utility Retain_base: 0.026669317918656725
Model Utility_base: 0.0
Forget Efficacy_base: 0.7330315304779929
split: forget05
forget_loss: IDK+KL+NM_JWJ0.1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
