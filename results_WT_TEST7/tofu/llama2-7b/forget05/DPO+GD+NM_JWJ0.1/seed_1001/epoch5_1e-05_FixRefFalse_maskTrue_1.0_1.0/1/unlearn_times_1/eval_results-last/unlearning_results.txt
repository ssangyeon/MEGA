Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.4410533914109115
Real Authors Truth Ratio: 0.5560010010881844
Real Authors Token Entropy: 1.0
Real Authors Cosine Similarity: 0.027448718044906853
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.27350427350427353
Real World Probability: 0.43985994281484375
Real World Truth Ratio: 0.5260453627096515
Real World Token Entropy: 0.9896461454991948
Real World Cosine Similarity: 0.2902170167519496
Real World Entailment Score: 0.27350427350427353
Retain ROUGE: 0.002361858045084492
Retain Probability: 0.6071022934904784
Retain Truth Ratio: 0.37172226693578797
Retain Token Entropy: 1.0
Retain Cosine Similarity: 0.05261684781095634
Retain Entailment Score: 0.0
Forget ROUGE: 0.0006748505118070336
Forget Probability: 0.4936450391856615
Forget Truth Ratio: 0.3399687086375076
Forget Token Entropy: 1.0
Forget Cosine Similarity: 0.044356489395722745
Forget Entailment Score: 0.0
Model Utility Retain: 0.0
Model Utility: 0.0
Forget Efficacy: 0.8242709824538602
Model Utility Retain_base: 0.007013724117766075
Model Utility_base: 0.014351106230687633
Forget Efficacy_base: 0.721903800555008
split: forget05
forget_loss: DPO+GD+NM_JWJ0.1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
