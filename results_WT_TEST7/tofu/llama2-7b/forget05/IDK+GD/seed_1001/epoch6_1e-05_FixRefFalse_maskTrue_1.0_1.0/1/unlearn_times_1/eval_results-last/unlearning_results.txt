Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.4570160530528549
Real Authors Truth Ratio: 0.5736398204556995
Real Authors Token Entropy: 0.9977447351943701
Real Authors Cosine Similarity: 0.02775796890258789
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.0
Real World Probability: 0.43913028892626904
Real World Truth Ratio: 0.5233668707388902
Real World Token Entropy: 0.9982970356912202
Real World Cosine Similarity: 0.011909000193461394
Real World Entailment Score: 0.0
Retain ROUGE: 0.029450964428627026
Retain Probability: 0.7735148754734432
Retain Truth Ratio: 0.4035566847609726
Retain Token Entropy: 0.9624956465813125
Retain Cosine Similarity: 0.08674963438572983
Retain Entailment Score: 0.02666666666666667
Forget ROUGE: 0.012825174225201918
Forget Probability: 0.6082147115274142
Forget Truth Ratio: 0.3715485058491891
Forget Token Entropy: 0.9702540599312802
Forget Cosine Similarity: 0.04731692023342475
Forget Entailment Score: 0.0
Model Utility Retain: 0.06834343185776061
Model Utility: 0.0
Forget Efficacy: 0.7920189376329541
Model Utility Retain_base: 0.07952178349828645
Model Utility_base: 0.0
Forget Efficacy_base: 0.6691372027993983
split: forget05
forget_loss: IDK+GD
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 6
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
