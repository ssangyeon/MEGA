Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.4353381565068722
Real Authors Truth Ratio: 0.5478475083024655
Real Authors Token Entropy: 1.0
Real Authors Cosine Similarity: 0.027448718044906853
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.16666666666666666
Real World Probability: 0.438046531022638
Real World Truth Ratio: 0.521025661011244
Real World Token Entropy: 0.9921756536664159
Real World Cosine Similarity: 0.19369347030535722
Real World Entailment Score: 0.1623931623931624
Retain ROUGE: 0.0032292689191615546
Retain Probability: 0.6029671832229525
Retain Truth Ratio: 0.3718972659125594
Retain Token Entropy: 1.0
Retain Cosine Similarity: 0.05178954334308704
Retain Entailment Score: 0.0
Forget ROUGE: 0.0023045452700473723
Forget Probability: 0.5043048117733475
Forget Truth Ratio: 0.3401927877964048
Forget Token Entropy: 1.0
Forget Cosine Similarity: 0.04478192699607462
Forget Entailment Score: 0.0
Model Utility Retain: 0.0
Model Utility: 0.0
Forget Efficacy: 0.821683185632825
Model Utility Retain_base: 0.00955368394435895
Model Utility_base: 0.017447286116530944
Forget Efficacy_base: 0.7177326183867334
split: forget05
forget_loss: DPO+NM_JWJ
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
