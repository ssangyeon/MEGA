Real Authors ROUGE: 0.9363333333333332
Real Authors Probability: 0.4896731109017054
Real Authors Truth Ratio: 0.618066620146553
Real Authors Token Entropy: 0.9865317118980482
Real Authors Cosine Similarity: 0.9658920335769653
Real Authors Entailment Score: 0.93
Real World ROUGE: 0.8746438746438747
Real World Probability: 0.45865892230002825
Real World Truth Ratio: 0.5536074387854665
Real World Token Entropy: 0.9665032239580384
Real World Cosine Similarity: 0.9528860938854706
Real World Entailment Score: 0.7692307692307693
Retain ROUGE: 0.8932506102201088
Retain Probability: 0.9685196700178071
Retain Truth Ratio: 0.44966010460042916
Retain Token Entropy: 0.9730682096813579
Retain Cosine Similarity: 0.9591562333206336
Retain Entailment Score: 0.94
Forget ROUGE: 0.9052074786118104
Forget Probability: 0.9602080771591539
Forget Truth Ratio: 0.4484051817640555
Forget Token Entropy: 0.969432426760157
Forget Cosine Similarity: 0.9734852315485477
Forget Entailment Score: 0.84
Model Utility Retain: 0.7989345214785563
Model Utility: 0.753882949935488
Forget Efficacy: 0.17453880618328643
Model Utility Retain_base: 0.6855713434968981
Model Utility_base: 0.632290611768642
Forget Efficacy_base: 0.22872642082166006
split: forget05
forget_loss: IDK+KL
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
