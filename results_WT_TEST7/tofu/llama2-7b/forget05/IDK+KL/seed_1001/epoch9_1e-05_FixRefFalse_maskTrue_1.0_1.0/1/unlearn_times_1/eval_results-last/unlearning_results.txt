Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.44312922474332417
Real Authors Truth Ratio: 0.5660475962877191
Real Authors Token Entropy: 1.0
Real Authors Cosine Similarity: 0.02829928781837225
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.0
Real World Probability: 0.43690855859711736
Real World Truth Ratio: 0.5258867713770317
Real World Token Entropy: 0.9995507928106948
Real World Cosine Similarity: 0.01149844617033616
Real World Entailment Score: 0.0
Retain ROUGE: 0.008618980795421798
Retain Probability: 0.5418102711832514
Retain Truth Ratio: 0.3776373692558349
Retain Token Entropy: 0.9787471422264628
Retain Cosine Similarity: 0.06166660106740892
Retain Entailment Score: 0.0
Forget ROUGE: 0.018120034340631554
Forget Probability: 0.39838779706699334
Forget Truth Ratio: 0.3355081768979292
Forget Token Entropy: 0.9875288351124243
Forget Cosine Similarity: 0.05693398813251406
Forget Entailment Score: 0.0
Model Utility Retain: 0.0
Model Utility: 0.0
Forget Efficacy: 0.8382100007123864
Model Utility Retain_base: 0.024892814336225325
Model Utility_base: 0.0
Forget Efficacy_base: 0.7493279972314819
split: forget05
forget_loss: IDK+KL
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 9
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
