Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.43585699800714456
Real Authors Truth Ratio: 0.5489711753841611
Real Authors Token Entropy: 1.0
Real Authors Cosine Similarity: 0.027448718044906853
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.18376068376068377
Real World Probability: 0.43733171277397936
Real World Truth Ratio: 0.5225329858151552
Real World Token Entropy: 0.9927924042203119
Real World Cosine Similarity: 0.1979749437708121
Real World Entailment Score: 0.1794871794871795
Retain ROUGE: 0.002276387959614406
Retain Probability: 0.5581480682834351
Retain Truth Ratio: 0.36378590682337403
Retain Token Entropy: 1.0
Retain Cosine Similarity: 0.052409189307751756
Retain Entailment Score: 0.0
Forget ROUGE: 0.0006748505118070336
Forget Probability: 0.4547802047580728
Forget Truth Ratio: 0.3310802365228315
Forget Token Entropy: 1.0
Forget Cosine Similarity: 0.044356489395722745
Forget Entailment Score: 0.0
Model Utility Retain: 0.0
Model Utility: 0.0
Forget Efficacy: 0.8338216437623132
Model Utility Retain_base: 0.00675930002680346
Model Utility_base: 0.013951518539627552
Forget Efficacy_base: 0.7378215694024295
split: forget05
forget_loss: DPO+KL+NM_JWJ0.1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
