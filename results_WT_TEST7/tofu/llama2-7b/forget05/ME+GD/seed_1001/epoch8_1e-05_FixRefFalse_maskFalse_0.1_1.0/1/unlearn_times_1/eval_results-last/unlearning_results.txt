Real Authors ROUGE: 0.9013333333333332
Real Authors Probability: 0.4772988934879684
Real Authors Truth Ratio: 0.6048184710663019
Real Authors Token Entropy: 0.9854223911398367
Real Authors Cosine Similarity: 0.9505764982104301
Real Authors Entailment Score: 0.89
Real World ROUGE: 0.8732193732193732
Real World Probability: 0.45407193340585933
Real World Truth Ratio: 0.5632504254864251
Real World Token Entropy: 0.9585296649604327
Real World Cosine Similarity: 0.9464267808147985
Real World Entailment Score: 0.6923076923076923
Retain ROUGE: 0.8237161433031908
Retain Probability: 0.9436435772224445
Retain Truth Ratio: 0.4417477966910431
Retain Token Entropy: 0.9677196782582295
Retain Cosine Similarity: 0.9341568843523661
Retain Entailment Score: 0.75
Forget ROUGE: 0.03230490163167569
Forget Probability: 0.005791457732031666
Forget Truth Ratio: 0.12446034403979911
Forget Token Entropy: 0.16102419390899694
Forget Cosine Similarity: 0.08056736519327387
Forget Entailment Score: 0.005
Model Utility Retain: 0.7523848583763629
Model Utility: 0.7290339187580517
Forget Efficacy: 0.9503751862806439
Model Utility Retain_base: 0.6611617299446767
Model Utility_base: 0.6199056621803302
Forget Efficacy_base: 0.9458144321988312
split: forget05
forget_loss: ME+GD
forget_coeff: 0.1
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 8
fix_ref_model: False
mask: False
unlearn_step: last
task_id: 1
unlearn_times: 1
