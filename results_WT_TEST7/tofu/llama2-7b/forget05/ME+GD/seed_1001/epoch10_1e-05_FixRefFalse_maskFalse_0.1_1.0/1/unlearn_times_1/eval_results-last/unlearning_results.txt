Real Authors ROUGE: 0.9063333333333332
Real Authors Probability: 0.4750386909511779
Real Authors Truth Ratio: 0.6014886608428958
Real Authors Token Entropy: 0.9861472963642328
Real Authors Cosine Similarity: 0.9453739887475967
Real Authors Entailment Score: 0.89
Real World ROUGE: 0.8675213675213675
Real World Probability: 0.451835878352981
Real World Truth Ratio: 0.5606858389896157
Real World Token Entropy: 0.9605076074914102
Real World Cosine Similarity: 0.9530602398081722
Real World Entailment Score: 0.7094017094017094
Retain ROUGE: 0.8111345738859731
Retain Probability: 0.9376141973439981
Retain Truth Ratio: 0.44296107104069676
Retain Token Entropy: 0.9686780637464381
Retain Cosine Similarity: 0.923959260135889
Retain Entailment Score: 0.74
Forget ROUGE: 0.0218812808170107
Forget Probability: 0.0032996152311101958
Forget Truth Ratio: 0.12063693416296561
Forget Token Entropy: 0.13050452829635462
Forget Cosine Similarity: 0.07717081570066511
Forget Entailment Score: 0.005
Model Utility Retain: 0.7478594950052752
Model Utility: 0.7276037046954416
Forget Efficacy: 0.9544022708176497
Model Utility Retain_base: 0.6583404842747629
Model Utility_base: 0.6173972208433056
Forget Efficacy_base: 0.9513940565963045
split: forget05
forget_loss: ME+GD
forget_coeff: 0.1
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 10
fix_ref_model: False
mask: False
unlearn_step: last
task_id: 1
unlearn_times: 1
