Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.4115830235879909
Real Authors Truth Ratio: 0.5081890602022772
Real Authors Token Entropy: 1.0
Real Authors Cosine Similarity: 0.027448718044906853
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.005698005698005697
Real World Probability: 0.411235419315734
Real World Truth Ratio: 0.48074331121401276
Real World Token Entropy: 0.9987875606895207
Real World Cosine Similarity: 0.017903706425020836
Real World Entailment Score: 0.0
Retain ROUGE: 0.00468651463252763
Retain Probability: 0.5022670673666988
Retain Truth Ratio: 0.3487639612162679
Retain Token Entropy: 1.0
Retain Cosine Similarity: 0.07649328211788088
Retain Entailment Score: 0.0
Forget ROUGE: 0.0034425922266762845
Forget Probability: 0.4443161853761357
Forget Truth Ratio: 0.3224215502939811
Forget Token Entropy: 1.0
Forget Cosine Similarity: 0.06927192650424938
Forget Entailment Score: 0.0
Model Utility Retain: 0.0
Model Utility: 0.0
Forget Efficacy: 0.8321095491197915
Model Utility Retain_base: 0.01374655922166076
Model Utility_base: 0.015250472394202725
Forget Efficacy_base: 0.7432732240344022
split: forget10
forget_loss: DPO+KL+NM_JWJ0.1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
