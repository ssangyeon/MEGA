Real Authors ROUGE: 0.005333333333333333
Real Authors Probability: 0.42283722645049715
Real Authors Truth Ratio: 0.5195736498607637
Real Authors Token Entropy: 1.0000000000000002
Real Authors Cosine Similarity: 0.049107640637084844
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.23076923076923078
Real World Probability: 0.4178250832007928
Real World Truth Ratio: 0.48596873837779614
Real World Token Entropy: 0.9904260170697964
Real World Cosine Similarity: 0.24785527628727066
Real World Entailment Score: 0.20512820512820512
Retain ROUGE: 0.0651517242632316
Retain Probability: 0.5851046885418908
Retain Truth Ratio: 0.367487568145944
Retain Token Entropy: 0.9972252665903659
Retain Cosine Similarity: 0.18672988372234006
Retain Entailment Score: 0.04666666666666667
Forget ROUGE: 0.012635481023510987
Forget Probability: 0.4753537926312188
Forget Truth Ratio: 0.3225512024220548
Forget Token Entropy: 0.9964090259192259
Forget Cosine Similarity: 0.11367642325038711
Forget Entailment Score: 0.0
Model Utility Retain: 0.1261411904653322
Model Utility: 0.0
Forget Efficacy: 0.8151566201345657
Model Utility Retain_base: 0.15167552699730164
Model Utility_base: 0.04084353325328488
Forget Efficacy_base: 0.7298198413077385
split: forget10
forget_loss: DPO+GD
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
