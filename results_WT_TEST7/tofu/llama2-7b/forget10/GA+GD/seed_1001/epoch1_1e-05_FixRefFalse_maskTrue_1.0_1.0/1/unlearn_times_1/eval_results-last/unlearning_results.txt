Real Authors ROUGE: 0.935
Real Authors Probability: 0.4789943828345224
Real Authors Truth Ratio: 0.6000629301905772
Real Authors Token Entropy: 0.9875428239987187
Real Authors Cosine Similarity: 0.9657025814056397
Real Authors Entailment Score: 0.87
Real World ROUGE: 0.8746438746438747
Real World Probability: 0.45012286278097197
Real World Truth Ratio: 0.560828016493924
Real World Token Entropy: 0.9631761917510131
Real World Cosine Similarity: 0.974857275812035
Real World Entailment Score: 0.8461538461538461
Retain ROUGE: 0.893933985996523
Retain Probability: 0.9563486829818661
Retain Truth Ratio: 0.46960853490731325
Retain Token Entropy: 0.968486108239911
Retain Cosine Similarity: 0.9564641561110815
Retain Entailment Score: 0.8366666666666667
Forget ROUGE: 0.7447559625791779
Forget Probability: 0.8731495150045832
Forget Truth Ratio: 0.4668062366963466
Forget Token Entropy: 0.9660345933397082
Forget Cosine Similarity: 0.9088850474357605
Forget Entailment Score: 0.6
Model Utility Retain: 0.7929162247231614
Model Utility: 0.7505587434018887
Forget Efficacy: 0.28128064765682637
Model Utility Retain_base: 0.6986935769665971
Model Utility_base: 0.6308944176889225
Forget Efficacy_base: 0.30509609523996417
split: forget10
forget_loss: GA+GD
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
