Real Authors ROUGE: 0.8443333333333334
Real Authors Probability: 0.43534673118835515
Real Authors Truth Ratio: 0.5471241119085011
Real Authors Token Entropy: 0.9384325258659512
Real Authors Cosine Similarity: 0.9140399557352066
Real Authors Entailment Score: 0.78
Real World ROUGE: 0.8532763532763533
Real World Probability: 0.407684373270315
Real World Truth Ratio: 0.49768528661401773
Real World Token Entropy: 0.9594996239217484
Real World Cosine Similarity: 0.9379580041282197
Real World Entailment Score: 0.6752136752136753
Retain ROUGE: 0.7572448025339008
Retain Probability: 0.8665928509684633
Retain Truth Ratio: 0.4372996007339657
Retain Token Entropy: 0.9655936317052687
Retain Cosine Similarity: 0.9028022475043933
Retain Entailment Score: 0.7
Forget ROUGE: 0.3333549282841774
Forget Probability: 0.23404799275333213
Forget Truth Ratio: 0.36178791681297395
Forget Token Entropy: 0.7551536310406713
Forget Cosine Similarity: 0.5745402894665798
Forget Entailment Score: 0.1
Model Utility Retain: 0.7200159132543278
Model Utility: 0.6842161111588962
Forget Efficacy: 0.6792537745365873
Model Utility Retain_base: 0.6300822572596482
Model Utility_base: 0.5730826489787344
Forget Efficacy_base: 0.6902697207165055
split: forget10
forget_loss: MK
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 6
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
