Real Authors ROUGE: 0.9413333333333332
Real Authors Probability: 0.4019881864191216
Real Authors Truth Ratio: 0.48907922363346634
Real Authors Token Entropy: 0.9860823512933133
Real Authors Cosine Similarity: 0.9558803308010101
Real Authors Entailment Score: 0.89
Real World ROUGE: 0.8774928774928774
Real World Probability: 0.39227872460976154
Real World Truth Ratio: 0.4784176684027653
Real World Token Entropy: 0.9596944516601184
Real World Cosine Similarity: 0.9470324964604826
Real World Entailment Score: 0.7264957264957265
Retain ROUGE: 0.7718162569078374
Retain Probability: 0.9029309223843794
Retain Truth Ratio: 0.45408968369960934
Retain Token Entropy: 0.9676491035998089
Retain Cosine Similarity: 0.913429995973905
Retain Entailment Score: 0.6966666666666667
Forget ROUGE: 0.39945724773587793
Forget Probability: 0.32152568426501443
Forget Truth Ratio: 0.3652551884712959
Forget Token Entropy: 0.9025078997568915
Forget Cosine Similarity: 0.6390008417516947
Forget Entailment Score: 0.14666666666666667
Model Utility Retain: 0.7344865827234928
Model Utility: 0.6869994360843129
Forget Efficacy: 0.6256188742218901
Model Utility Retain_base: 0.6514151925123488
Model Utility_base: 0.5632386687266634
Forget Efficacy_base: 0.6379206265092705
split: forget10
forget_loss: MK
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 7
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
