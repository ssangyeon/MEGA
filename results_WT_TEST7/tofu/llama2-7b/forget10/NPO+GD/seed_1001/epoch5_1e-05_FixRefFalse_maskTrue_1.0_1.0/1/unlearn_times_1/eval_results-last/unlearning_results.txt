Real Authors ROUGE: 0.9259999999999999
Real Authors Probability: 0.4409323415450055
Real Authors Truth Ratio: 0.5603741929603883
Real Authors Token Entropy: 0.8200160340357461
Real Authors Cosine Similarity: 0.7016856750845909
Real Authors Entailment Score: 0.65
Real World ROUGE: 0.8888888888888888
Real World Probability: 0.43112174168175127
Real World Truth Ratio: 0.5445255208599976
Real World Token Entropy: 0.8040208143977543
Real World Cosine Similarity: 0.7717170817220312
Real World Entailment Score: 0.452991452991453
Retain ROUGE: 0.44622293788821954
Retain Probability: 0.339219728639178
Retain Truth Ratio: 0.3492051796415789
Retain Token Entropy: 0.7118191903655571
Retain Cosine Similarity: 0.6169825065135955
Retain Entailment Score: 0.6266666666666667
Forget ROUGE: 0.26988653286982434
Forget Probability: 0.13352060268660296
Forget Truth Ratio: 0.28506246131252055
Forget Token Entropy: 0.47962598155205416
Forget Cosine Similarity: 0.44838429110745587
Forget Entailment Score: 0.09
Model Utility Retain: 0.4734098589999461
Model Utility: 0.5621916167068287
Forget Efficacy: 0.7546292224047193
Model Utility Retain_base: 0.3725495568960259
Model Utility_base: 0.4873830413498058
Forget Efficacy_base: 0.7705101343770174
split: forget10
forget_loss: NPO+GD
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
