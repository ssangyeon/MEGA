Real Authors ROUGE,Real Authors Probability,Real Authors Truth Ratio,Real Authors Token Entropy,Real Authors Cosine Similarity,Real Authors Entailment Score,Real World ROUGE,Real World Probability,Real World Truth Ratio,Real World Token Entropy,Real World Cosine Similarity,Real World Entailment Score,Retain ROUGE,Retain Probability,Retain Truth Ratio,Retain Token Entropy,Retain Cosine Similarity,Retain Entailment Score,Forget ROUGE,Forget Probability,Forget Truth Ratio,Forget Token Entropy,Forget Cosine Similarity,Forget Entailment Score,Model Utility Retain,Model Utility,Forget Efficacy,Model Utility Retain_base,Model Utility_base,Forget Efficacy_base,split,forget_loss,forget_coeff,regularization_coeff,learning_rate,epochs,fix_ref_model,mask,unlearn_step,task_id,unlearn_times
0.935,0.5040616579469153,0.6372008064256885,0.9856980654043107,0.9644511783123016,0.87,0.8746438746438747,0.46272521265448313,0.5723184141290301,0.9620815888602393,0.9500798048117222,0.7264957264957265,0.8975239690553303,0.946018535053196,0.4361247452562186,0.9705046766304902,0.957549791932106,0.8433333333333334,0.40535972465491155,0.3768154036891521,0.35757752208562044,0.8511463831276717,0.6045407250026862,0.22333333333333333,0.7767337519128622,0.7478700185660823,0.6064746582468593,0.6720189149167533,0.636553515456143,0.6200824498567721,forget10,ME+GD,0.1,1.0,1e-05,2,False,False,last,1,1
Real Authors ROUGE,Real Authors Probability,Real Authors Truth Ratio,Real Authors Token Entropy,Real Authors Cosine Similarity,Real Authors Entailment Score,Real World ROUGE,Real World Probability,Real World Truth Ratio,Real World Token Entropy,Real World Cosine Similarity,Real World Entailment Score,Retain ROUGE,Retain Probability,Retain Truth Ratio,Retain Token Entropy,Retain Cosine Similarity,Retain Entailment Score,Forget ROUGE,Forget Probability,Forget Truth Ratio,Forget Token Entropy,Forget Cosine Similarity,Forget Entailment Score,Model Utility Retain,Model Utility,Forget Efficacy,Model Utility Retain_base,Model Utility_base,Forget Efficacy_base,split,forget_loss,forget_coeff,regularization_coeff,learning_rate,epochs,fix_ref_model,mask,unlearn_step,task_id,unlearn_times
0.935,0.5040616579469153,0.6372008064256885,0.9856980654043107,0.9644511783123016,0.87,0.8746438746438747,0.46272521265448313,0.5723184141290301,0.9620815888602393,0.9500798048117222,0.7264957264957265,0.8975239690553303,0.946018535053196,0.4361247452562186,0.9705046766304902,0.957549791932106,0.8433333333333334,0.40535972465491155,0.3768154036891521,0.35757752208562044,0.8511463831276717,0.6045407250026862,0.22333333333333333,0.7767337519128622,0.7478700185660823,0.6064746582468593,0.6720189149167533,0.636553515456143,0.6200824498567721,forget10,ME+GD,0.1,1.0,1e-05,2,False,False,last,1,1
