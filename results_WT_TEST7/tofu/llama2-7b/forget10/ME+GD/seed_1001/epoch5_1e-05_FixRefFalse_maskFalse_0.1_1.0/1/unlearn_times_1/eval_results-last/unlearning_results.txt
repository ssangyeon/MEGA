Real Authors ROUGE: 0.8933333333333333
Real Authors Probability: 0.4697537921380952
Real Authors Truth Ratio: 0.5935322722991285
Real Authors Token Entropy: 0.9849641602467891
Real Authors Cosine Similarity: 0.9602297022938728
Real Authors Entailment Score: 0.84
Real World ROUGE: 0.8974358974358975
Real World Probability: 0.43671224943767806
Real World Truth Ratio: 0.5460089046990345
Real World Token Entropy: 0.9618021829680404
Real World Cosine Similarity: 0.9491684890200949
Real World Entailment Score: 0.7435897435897436
Retain ROUGE: 0.8596726662587039
Retain Probability: 0.945604060864939
Retain Truth Ratio: 0.44473164425624134
Retain Token Entropy: 0.9679579889204871
Retain Cosine Similarity: 0.9404785359899203
Retain Entailment Score: 0.76
Forget ROUGE: 0.03703354657753223
Forget Probability: 0.008951251608206208
Forget Truth Ratio: 0.10293685861551694
Forget Token Entropy: 0.16254340326730818
Forget Cosine Similarity: 0.09294684634233515
Forget Entailment Score: 0.0033333333333333335
Model Utility Retain: 0.7612777439349288
Model Utility: 0.7277036927496509
Forget Efficacy: 0.9509596327046153
Model Utility Retain_base: 0.6712452292547899
Model Utility_base: 0.6148420178046092
Forget Efficacy_base: 0.9503594477329149
split: forget10
forget_loss: ME+GD
forget_coeff: 0.1
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: False
unlearn_step: last
task_id: 1
unlearn_times: 1
