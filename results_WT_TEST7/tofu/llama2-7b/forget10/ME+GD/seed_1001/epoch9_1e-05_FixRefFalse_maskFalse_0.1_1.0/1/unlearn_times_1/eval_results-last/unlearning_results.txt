Real Authors ROUGE: 0.9213333333333332
Real Authors Probability: 0.4677737247826081
Real Authors Truth Ratio: 0.5867309461816204
Real Authors Token Entropy: 0.9866553602712781
Real Authors Cosine Similarity: 0.9626427978277207
Real Authors Entailment Score: 0.88
Real World ROUGE: 0.8760683760683761
Real World Probability: 0.43842325704093055
Real World Truth Ratio: 0.5355935814964847
Real World Token Entropy: 0.9637734467295394
Real World Cosine Similarity: 0.9546292352880168
Real World Entailment Score: 0.7692307692307693
Retain ROUGE: 0.7981478664929332
Retain Probability: 0.9233957151816983
Retain Truth Ratio: 0.43091218879652216
Retain Token Entropy: 0.967559714780179
Retain Cosine Similarity: 0.9175603659947713
Retain Entailment Score: 0.6966666666666667
Forget ROUGE: 0.033244407442716305
Forget Probability: 0.005527692542500044
Forget Truth Ratio: 0.09520751832671637
Forget Token Entropy: 0.10993538176595709
Forget Cosine Similarity: 0.0885328811655442
Forget Entailment Score: 0.0033333333333333335
Model Utility Retain: 0.730344635505351
Model Utility: 0.7198246430957794
Forget Efficacy: 0.9548308334378379
Model Utility Retain_base: 0.6442581622306748
Model Utility_base: 0.6051031154099238
Forget Efficacy_base: 0.9553401272293558
split: forget10
forget_loss: ME+GD
forget_coeff: 0.1
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 9
fix_ref_model: False
mask: False
unlearn_step: last
task_id: 1
unlearn_times: 1
