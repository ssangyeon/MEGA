Real Authors ROUGE: 0.9113333333333332
Real Authors Probability: 0.5001017280732127
Real Authors Truth Ratio: 0.6334171767413483
Real Authors Token Entropy: 0.984319286759145
Real Authors Cosine Similarity: 0.958483356833458
Real Authors Entailment Score: 0.83
Real World ROUGE: 0.8675213675213675
Real World Probability: 0.4571094309272021
Real World Truth Ratio: 0.5571630419739136
Real World Token Entropy: 0.9614664384648286
Real World Cosine Similarity: 0.954146568591778
Real World Entailment Score: 0.717948717948718
Retain ROUGE: 0.7697092957061934
Retain Probability: 0.8889067125459226
Retain Truth Ratio: 0.4162464870178356
Retain Token Entropy: 0.9685579979056244
Retain Cosine Similarity: 0.8975215890010197
Retain Entailment Score: 0.66
Forget ROUGE: 0.12369545651010398
Forget Probability: 0.0005334314974036301
Forget Truth Ratio: 0.422219992092171
Forget Token Entropy: 0.6824181765728683
Forget Cosine Similarity: 0.2836149962618947
Forget Entailment Score: 0.05
Model Utility Retain: 0.7068482028292136
Model Utility: 0.7187280466229963
Forget Efficacy: 0.8239872247276854
Model Utility Retain_base: 0.6215565877312227
Model Utility_base: 0.614863594205258
Forget Efficacy_base: 0.8178503733001071
split: forget01
forget_loss: MK
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-05
epochs: 10
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
