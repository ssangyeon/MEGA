Real Authors ROUGE: 0.9263333333333332
Real Authors Probability: 0.4887307529257947
Real Authors Truth Ratio: 0.6178367477086644
Real Authors Token Entropy: 0.9862768487674469
Real Authors Cosine Similarity: 0.9596414077281952
Real Authors Entailment Score: 0.92
Real World ROUGE: 0.8717948717948718
Real World Probability: 0.45638286739578526
Real World Truth Ratio: 0.54932952919315
Real World Token Entropy: 0.9668795611150117
Real World Cosine Similarity: 0.9493423170513577
Real World Entailment Score: 0.7692307692307693
Retain ROUGE: 0.8878154985757718
Retain Probability: 0.965809006419507
Retain Truth Ratio: 0.4500167920398825
Retain Token Entropy: 0.9735530794146141
Retain Cosine Similarity: 0.9577412482599418
Retain Entailment Score: 0.9466666666666667
Forget ROUGE: 0.35487138768491844
Forget Probability: 0.8406930202483387
Forget Truth Ratio: 0.3999154562147085
Forget Token Entropy: 0.9759319038463751
Forget Cosine Similarity: 0.5881397923221812
Forget Entailment Score: 0.125
Model Utility Retain: 0.7987722769178608
Model Utility: 0.7517269563319517
Forget Efficacy: 0.5382760687059707
Model Utility Retain_base: 0.6843220451890273
Model Utility_base: 0.6299567406861847
Forget Efficacy_base: 0.46817337861734487
split: forget01
forget_loss: DPO+KL+NM_JWJ0.1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
