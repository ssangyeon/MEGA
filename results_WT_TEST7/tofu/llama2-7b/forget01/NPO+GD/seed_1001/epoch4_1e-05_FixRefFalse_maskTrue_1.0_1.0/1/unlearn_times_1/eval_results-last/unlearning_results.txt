Real Authors ROUGE: 0.9329999999999999
Real Authors Probability: 0.41670015682463657
Real Authors Truth Ratio: 0.5206531909805063
Real Authors Token Entropy: 0.9760182941897366
Real Authors Cosine Similarity: 0.9549004611372948
Real Authors Entailment Score: 0.87
Real World ROUGE: 0.8732193732193732
Real World Probability: 0.40556452485692024
Real World Truth Ratio: 0.5168855614385215
Real World Token Entropy: 0.9436650306332949
Real World Cosine Similarity: 0.9452078006206415
Real World Entailment Score: 0.6752136752136753
Retain ROUGE: 0.9273323544974119
Retain Probability: 0.9466467026711147
Retain Truth Ratio: 0.48553056202314215
Retain Token Entropy: 0.9604602497362479
Retain Cosine Similarity: 0.956964945991834
Retain Entailment Score: 0.6633333333333333
Forget ROUGE: 0.48206305381270126
Forget Probability: 0.26351937316367485
Forget Truth Ratio: 0.41193741539127815
Forget Token Entropy: 0.9357358509426346
Forget Cosine Similarity: 0.798657999932766
Forget Entailment Score: 0.35
Model Utility Retain: 0.7704159785515704
Model Utility: 0.7046184909774859
Forget Efficacy: 0.5387644315399159
Model Utility Retain_base: 0.7152521700265568
Model Utility_base: 0.5947598323836298
Forget Efficacy_base: 0.6141600525441153
split: forget01
forget_loss: NPO+GD
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
