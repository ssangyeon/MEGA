Real Authors ROUGE: 0.9179999999999999
Real Authors Probability: 0.5055294562359702
Real Authors Truth Ratio: 0.6342103554725468
Real Authors Token Entropy: 0.986444207094718
Real Authors Cosine Similarity: 0.9588480842113495
Real Authors Entailment Score: 0.87
Real World ROUGE: 0.8888888888888888
Real World Probability: 0.46729454790208935
Real World Truth Ratio: 0.5651487161680013
Real World Token Entropy: 0.9598073583233622
Real World Cosine Similarity: 0.9569303459591336
Real World Entailment Score: 0.6923076923076923
Retain ROUGE: 0.8121957928304548
Retain Probability: 0.9240392646121424
Retain Truth Ratio: 0.43582050451184867
Retain Token Entropy: 0.9672681000981542
Retain Cosine Similarity: 0.9306332272291183
Retain Entailment Score: 0.7366666666666667
Forget ROUGE: 0.018478260869565215
Forget Probability: 0.0004669650562265826
Forget Truth Ratio: 0.10041766803726593
Forget Token Entropy: 0.05580773308204175
Forget Cosine Similarity: 0.07648115204647184
Forget Entailment Score: 0.0
Model Utility Retain: 0.7431444288102355
Model Utility: 0.7349983550349122
Forget Efficacy: 0.9608311907980941
Model Utility Retain_base: 0.6510476126161693
Model Utility_base: 0.6299611984922548
Forget Efficacy_base: 0.9602123686789807
split: forget01
forget_loss: ME+GD
forget_coeff: 0.1
regularization_coeff: 1.0
learning_rate: 2e-05
epochs: 10
fix_ref_model: False
mask: False
unlearn_step: last
task_id: 1
unlearn_times: 1
