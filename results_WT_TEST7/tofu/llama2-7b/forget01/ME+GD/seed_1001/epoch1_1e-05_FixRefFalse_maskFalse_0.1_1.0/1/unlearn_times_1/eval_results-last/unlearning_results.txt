Real Authors ROUGE: 0.9329999999999999
Real Authors Probability: 0.4584847922171559
Real Authors Truth Ratio: 0.5770836922663228
Real Authors Token Entropy: 0.985812002823997
Real Authors Cosine Similarity: 0.9948663300275803
Real Authors Entailment Score: 0.94
Real World ROUGE: 0.8746438746438747
Real World Probability: 0.430714357065383
Real World Truth Ratio: 0.5440505897936191
Real World Token Entropy: 0.9589202235891117
Real World Cosine Similarity: 0.9883783739856166
Real World Entailment Score: 0.8461538461538461
Retain ROUGE: 0.9873547730212628
Retain Probability: 0.9892832160354006
Retain Truth Ratio: 0.4743266112414273
Retain Token Entropy: 0.9694495124953108
Retain Cosine Similarity: 0.9910650356610616
Retain Entailment Score: 0.9766666666666667
Forget ROUGE: 0.9529608353471207
Forget Probability: 0.9891158230945386
Forget Truth Ratio: 0.4541184859149213
Forget Token Entropy: 0.9685243937456531
Forget Cosine Similarity: 0.9888126984238624
Forget Entailment Score: 0.95
Model Utility Retain: 0.8337604581092313
Model Utility: 0.756144283290987
Forget Efficacy: 0.13299843144391144
Model Utility Retain_base: 0.726059636038372
Model Utility_base: 0.6241001319224175
Forget Efficacy_base: 0.20126828521447315
split: forget01
forget_loss: ME+GD
forget_coeff: 0.1
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: False
mask: False
unlearn_step: last
task_id: 1
unlearn_times: 1
