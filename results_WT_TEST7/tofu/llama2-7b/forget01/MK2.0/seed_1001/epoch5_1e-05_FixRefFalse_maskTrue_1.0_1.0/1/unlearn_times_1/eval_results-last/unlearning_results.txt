Real Authors ROUGE: 0.903
Real Authors Probability: 0.48509329569794046
Real Authors Truth Ratio: 0.6086121652291481
Real Authors Token Entropy: 0.9849585855941083
Real Authors Cosine Similarity: 0.9596073848009109
Real Authors Entailment Score: 0.82
Real World ROUGE: 0.8703703703703705
Real World Probability: 0.45331496607695376
Real World Truth Ratio: 0.5660228455135616
Real World Token Entropy: 0.959339791879569
Real World Cosine Similarity: 0.9675681881415539
Real World Entailment Score: 0.7692307692307693
Retain ROUGE: 0.9520699053160617
Retain Probability: 0.9638762344534416
Retain Truth Ratio: 0.454039984317259
Retain Token Entropy: 0.9699947767390673
Retain Cosine Similarity: 0.9800642482439677
Retain Entailment Score: 0.9233333333333333
Forget ROUGE: 0.3459016808618428
Forget Probability: 0.22662988921607816
Forget Truth Ratio: 0.34115254409649765
Forget Token Entropy: 0.961718861931463
Forget Cosine Similarity: 0.6843330681324005
Forget Entailment Score: 0.225
Model Utility Retain: 0.8081268483365531
Model Utility: 0.7496583446722315
Forget Efficacy: 0.6353965635386362
Model Utility Retain_base: 0.6992567164743231
Model Utility_base: 0.6327399821839161
Forget Efficacy_base: 0.6954386286085271
split: forget01
forget_loss: MK2.0
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
