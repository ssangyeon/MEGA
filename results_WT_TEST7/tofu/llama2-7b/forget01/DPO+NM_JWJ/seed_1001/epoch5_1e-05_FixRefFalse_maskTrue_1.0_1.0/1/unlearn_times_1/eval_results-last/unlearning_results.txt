Real Authors ROUGE: 0.9263333333333332
Real Authors Probability: 0.48826207223731016
Real Authors Truth Ratio: 0.6160652894306625
Real Authors Token Entropy: 0.9862768487674469
Real Authors Cosine Similarity: 0.9606015133857727
Real Authors Entailment Score: 0.92
Real World ROUGE: 0.8831908831908832
Real World Probability: 0.4567916735969715
Real World Truth Ratio: 0.5512825710708428
Real World Token Entropy: 0.9665044404418889
Real World Cosine Similarity: 0.9533511491922232
Real World Entailment Score: 0.7777777777777778
Retain ROUGE: 0.8934093049438131
Retain Probability: 0.9663499549154236
Retain Truth Ratio: 0.44907632554139165
Retain Token Entropy: 0.9730484356871913
Retain Cosine Similarity: 0.9593708152075608
Retain Entailment Score: 0.9433333333333334
Forget ROUGE: 0.32061548957317354
Forget Probability: 0.8364545572718635
Forget Truth Ratio: 0.3981356851800435
Forget Token Entropy: 0.9794562414381364
Forget Cosine Similarity: 0.5104410259751603
Forget Entailment Score: 0.125
Model Utility Retain: 0.7988240116228812
Model Utility: 0.752872525787491
Forget Efficacy: 0.5618706483999518
Model Utility Retain_base: 0.6847872706851642
Model Utility_base: 0.6308208915022271
Forget Efficacy_base: 0.48159808932497317
split: forget01
forget_loss: DPO+NM_JWJ
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
