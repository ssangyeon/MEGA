Real Authors ROUGE: 0.9129999999999999
Real Authors Probability: 0.4710390707570755
Real Authors Truth Ratio: 0.5958276101488194
Real Authors Token Entropy: 0.9842930210322588
Real Authors Cosine Similarity: 0.9464586764574051
Real Authors Entailment Score: 0.85
Real World ROUGE: 0.9002849002849004
Real World Probability: 0.4443306962571313
Real World Truth Ratio: 0.5412221901106059
Real World Token Entropy: 0.9587247658805061
Real World Cosine Similarity: 0.9522786232141348
Real World Entailment Score: 0.7264957264957265
Retain ROUGE: 0.7815846307161107
Retain Probability: 0.9457872325171366
Retain Truth Ratio: 0.4349757756945773
Retain Token Entropy: 0.9721462319115871
Retain Cosine Similarity: 0.831871433875834
Retain Entailment Score: 0.7266666666666667
Forget ROUGE: 0.0760817911651149
Forget Probability: 0.7669295197840691
Forget Truth Ratio: 0.36654680845207765
Forget Token Entropy: 0.9953529091774523
Forget Cosine Similarity: 0.11128338894341142
Forget Entailment Score: 0.05
Model Utility Retain: 0.7279205071205838
Model Utility: 0.7180786516661877
Forget Efficacy: 0.7258316983310653
Model Utility Retain_base: 0.6471443586628753
Model Utility_base: 0.6105275084516985
Forget Efficacy_base: 0.5968139601995794
split: forget01
forget_loss: NM_JWJ2.0
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 10
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
