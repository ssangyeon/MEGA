Real Authors ROUGE: 0.8563333333333333
Real Authors Probability: 0.47302174589392487
Real Authors Truth Ratio: 0.5918531591682976
Real Authors Token Entropy: 0.9878137021200734
Real Authors Cosine Similarity: 0.8971222690306604
Real Authors Entailment Score: 0.84
Real World ROUGE: 0.8660968660968662
Real World Probability: 0.44570653622780887
Real World Truth Ratio: 0.5389458923864725
Real World Token Entropy: 0.9658567294861198
Real World Cosine Similarity: 0.9476134124984089
Real World Entailment Score: 0.7777777777777778
Retain ROUGE: 0.4482545490249469
Retain Probability: 0.935750839605854
Retain Truth Ratio: 0.44757578575212015
Retain Token Entropy: 0.9878778275232422
Retain Cosine Similarity: 0.527624736938936
Retain Entailment Score: 0.49333333333333335
Forget ROUGE: 0.008601217010021464
Forget Probability: 0.7184887341443058
Forget Truth Ratio: 0.38806225424071383
Forget Token Entropy: 0.9976466914542541
Forget Cosine Similarity: 0.023645232990384103
Forget Entailment Score: 0.0
Model Utility Retain: 0.5731546565373365
Model Utility: 0.6572373222414907
Forget Efficacy: 0.772240512322915
Model Utility Retain_base: 0.5421235088642002
Model Utility_base: 0.5711041214320665
Forget Efficacy_base: 0.6282825982016529
split: forget01
forget_loss: IDK+KL+NM_JWJ0.2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: False
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
